{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8617a876-e18b-4e7a-a56c-bde6bb0ec980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import svm \n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d6d97f-4fc0-48d6-8544-1a5aad6e7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subject_line(text):\n",
    "    return '\\r\\n'.join(line for line in text.split('\\r\\n') if not line.startswith('Subject:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"text\": \"INFO\", \"label\": \"LABEL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['INFO'] = df['INFO'].apply(remove_subject_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "ham     0.710114\n",
       "spam    0.289886\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LABEL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4137, 3)\n",
      "(1034, 3)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = df.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Split into training and test sets\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "ham     0.707276\n",
       "spam    0.292724\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['LABEL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "ham     0.72147\n",
       "spam    0.27853\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['LABEL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After cleaning\n",
    "training_set['INFO'] = training_set['INFO'].str.replace(\n",
    "   '\\W', ' ') # Removes punctuation\n",
    "training_set['INFO'] = training_set['INFO'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['INFO'] = training_set['INFO'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['INFO']:\n",
    "   for word in sms:\n",
    "      vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_text = {unique_word: [0] * len(training_set['INFO']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['INFO']):\n",
    "   for word in sms:\n",
    "      word_counts_per_text[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['label_num'] == 1]\n",
    "ham_messages = training_set_clean[training_set_clean['label_num'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['INFO'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['INFO'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "   n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
    "   p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "   parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "   n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
    "   p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "   parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, parameters_spam, parameters_ham, p_spam, p_ham):\n",
    "        self.parameters_spam = parameters_spam\n",
    "        self.parameters_ham = parameters_ham\n",
    "        self.p_spam = p_spam\n",
    "        self.p_ham = p_ham\n",
    "\n",
    "    def classify(self, message):\n",
    "        message = re.sub('\\W', ' ', message)\n",
    "        message = message.lower().split()\n",
    "\n",
    "        p_spam_given_message = self.p_spam\n",
    "        p_ham_given_message = self.p_ham\n",
    "\n",
    "        for word in message:\n",
    "            if word in self.parameters_spam:\n",
    "                p_spam_given_message *= self.parameters_spam[word]\n",
    "\n",
    "            if word in self.parameters_ham:\n",
    "                p_ham_given_message *= self.parameters_ham[word]\n",
    "\n",
    "        if p_ham_given_message > p_spam_given_message:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier(parameters_spam, parameters_ham, p_spam, p_ham)\n",
    "classifier.classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "   '''\n",
    "   message: a string\n",
    "   '''\n",
    "\n",
    "   message = re.sub('\\W', ' ', message)\n",
    "   message = message.lower().split()\n",
    "\n",
    "   p_spam_given_message = p_spam\n",
    "   p_ham_given_message = p_ham\n",
    "\n",
    "   for word in message:\n",
    "      if word in parameters_spam:\n",
    "         p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "      if word in parameters_ham:\n",
    "         p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "   if p_ham_given_message > p_spam_given_message:\n",
    "      return 'ham'\n",
    "   elif p_spam_given_message > p_ham_given_message:\n",
    "      return 'spam'\n",
    "   else:\n",
    "      return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>INFO</th>\n",
       "      <th>label_num</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>teco tap 115 . 000 / hpl iferc ; 10 . 000 / en...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>having trouble reading\\r\\nthis e - mail ? clic...</td>\n",
       "      <td>1</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>done .\\r\\ndaren j farmer @ ect\\r\\n06 / 29 / 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>this message will inform you on how to remove ...</td>\n",
       "      <td>1</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>microsoft windows xp professional 2002 $ 50 re...</td>\n",
       "      <td>1</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>spam</td>\n",
       "      <td>driving at ? in 1876\\r\\ndogs and cats that ' s...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>ham</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>spam</td>\n",
       "      <td>hi ,\\r\\nregalis , also known as superviagra or...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>ham</td>\n",
       "      <td>please make sure this is clearly understood by...</td>\n",
       "      <td>0</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>ham</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1034 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LABEL                                               INFO  label_num  \\\n",
       "0      ham  teco tap 115 . 000 / hpl iferc ; 10 . 000 / en...          0   \n",
       "1     spam  having trouble reading\\r\\nthis e - mail ? clic...          1   \n",
       "2      ham  done .\\r\\ndaren j farmer @ ect\\r\\n06 / 29 / 20...          0   \n",
       "3     spam  this message will inform you on how to remove ...          1   \n",
       "4     spam  microsoft windows xp professional 2002 $ 50 re...          1   \n",
       "...    ...                                                ...        ...   \n",
       "1029  spam  driving at ? in 1876\\r\\ndogs and cats that ' s...          1   \n",
       "1030   ham  - - - - - - - - - - - - - - - - - - - - - - fo...          0   \n",
       "1031  spam  hi ,\\r\\nregalis , also known as superviagra or...          1   \n",
       "1032   ham  please make sure this is clearly understood by...          0   \n",
       "1033   ham  - - - - - - - - - - - - - - - - - - - - - - fo...          0   \n",
       "\n",
       "                       predicted  \n",
       "0                            ham  \n",
       "1     needs human classification  \n",
       "2     needs human classification  \n",
       "3     needs human classification  \n",
       "4     needs human classification  \n",
       "...                          ...  \n",
       "1029                        spam  \n",
       "1030                         ham  \n",
       "1031                        spam  \n",
       "1032  needs human classification  \n",
       "1033                         ham  \n",
       "\n",
       "[1034 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['INFO'].apply(classify_test_set)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 568\n",
      "Incorrect: 466\n",
      "Accuracy: 0.5493230174081238\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "   row = row[1]\n",
    "   if row['LABEL'] == row['predicted']:\n",
    "      correct += 1\n",
    "\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55859271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p_ham.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(parameters_spam, \"parameters_spam.joblib\")\n",
    "joblib.dump(parameters_ham, \"parameters_ham.joblib\")\n",
    "joblib.dump(p_spam, \"p_spam.joblib\")\n",
    "joblib.dump(p_ham, \"p_ham.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
